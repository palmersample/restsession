name: Test
on:
  workflow_call:
    inputs:
      python-version:
        required: true
        type: string
      poetry-cache-key:
        required: true
        type: string
      project-name:
        required: true
        type: string
      project-version:
        required: true
        type: string

jobs:
  test:
    name: Perform all code tests
    runs-on: ubuntu-latest
    steps:
      - name: Pull the tests directory from the repo
        uses: actions/checkout@v4
        with:
          sparse-checkout: |
            tests
            pyproject.toml
            poetry.lock
          sparse-checkout-cone-mode: false

      - name: Load cached Poetry installation
        id: cached-poetry
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: ${{ inputs.poetry-cache-key }}

      - name: Load package cache
        uses: actions/cache@v4
        id: cached-poetry-venv
        with:
          path: .venv
          key: venv-${{ runner.os }}-python${{ inputs.python-version }}-testing

      - name: Activate venv for all tasks
        run: |
          echo "PATH=${GITHUB_WORKSPACE}/.venv/bin:$PATH" >> $GITHUB_ENV
          echo "VIRTUAL_ENV=${GITHUB_WORKSPACE}/.venv" >> $GITHUB_ENV

      - name: Verify Python version
        run: |
          python -V

      - name: Install wheel from TestPyPi
        run: |
          pip install --index-url https://test.pypi.org/simple/ --no-deps ${{ inputs.project-name }}

      - name: Prepare pytest cache
        uses: actions/cache@v4
        id: pytest-cache
        with:
          path: .pytest_cache
          key: pytest-${{ runner.os }}-${{ inputs.python-version }}-${{ inputs.build-wheel-name }}

      # If all tests passed and this is an existing wheel, instruct pytest to
      # not run all tests again. Useful for non-code changes (e.g. pipeline
      # task changes)
      - name: Run failed pytest results
        run: pytest --last-failed --last-failed-no-failures none tests
        if: steps.pytest-cache.outputs.cache-hit == 'true'

      - name: Clear pytest cache for new builds
        run: pytest --cache-clear
        if: steps.pytest-cache.outputs.cache-hit != 'true'
